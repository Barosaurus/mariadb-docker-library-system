1 Einleitung 

1.1 Hintergrund und Motivation 

In einer Zeit, in der Anwendungen und Dienste immer häufiger in verteilten, dynamischen Umgebungen betrieben werden, steigt die Bedeutung von flexiblen und skalierbaren Datenbanksystemen stetig an. Daten bilden dabei die Grundlage nahezu jeder digitalen Anwendung und müssen zuverlässig, performant und sicher verarbeitet werden. Gleichzeitig stehen Entwickler und IT-Abteilungen vor der Herausforderung, Datenbanksysteme so zu betreiben, dass sie sich schnell an veränderte Anforderungen anpassen lassen und gleichzeitig einfach zu warten sind. 

Die Containerisierung hat sich in den letzten Jahren als zukunftsweisender Ansatz etabliert, um Anwendungen und ihre Abhängigkeiten isoliert, reproduzierbar und plattformunabhängig bereitzustellen. Besonders in Entwicklungs- und Testumgebungen ermöglicht der Einsatz von Containern wie denen der Plattform Docker eine erhebliche Vereinfachung von Installations- und Konfigurationsaufwänden (Merkel, 2014). Auch im produktiven Betrieb versprechen containerisierte Architekturen Vorteile in Bezug auf Portabilität, Skalierbarkeit und Ressourcennutzung (Pahl, 2015). 

Mit MariaDB wird in dieser Arbeit ein relationales Open-Source-Datenbanksystem betrachtet, das sich durch seine Flexibilität und eine starke Community auszeichnet. Als Abspaltung (Fork) des weit verbreiteten MySQL-Systems wird MariaDB weltweit in vielen Unternehmen eingesetzt und eignet sich hervorragend als Beispiel für die praktische Containerisierung von Datenbanken (Widenius et al., 2012). 

Ziel dieser Arbeit ist es, anhand eines prototypischen Anwendungsfalls die Möglichkeiten und Herausforderungen beim Betrieb einer MariaDB-Datenbank in einer containerisierten Umgebung zu untersuchen. Dazu wird ein einfacher Microservice entwickelt, der mit einer MariaDB-Instanz kommuniziert und grundlegende Datenbankoperationen – Create, Read, Update und Delete (CRUD) – innerhalb eines Docker-Containers demonstriert. Besonderer Fokus liegt auf der Frage, wie sich durch den Einsatz von Containern Entwicklungsprozesse vereinfachen und Deployment-Abläufe standardisieren lassen. 

Die zentrale Leitfrage lautet daher: Wie kann die Containerisierung von MariaDB mit Docker dazu beitragen, Entwicklungs- und Betriebsprozesse von datenbankbasierten Anwendungen effizienter, skalierbarer und portabler zu gestalten? 

Die Arbeit gliedert sich wie folgt: Im zweiten Kapitel werden zunächst die theoretischen Grundlagen zu MariaDB, Docker und dem Konzept der Containerisierung erläutert. Kapitel 3 beschreibt die konkrete Umsetzung des Prototyps mit Fokus auf Architektur, Konfiguration und technischer Realisierung. Kapitel 4 liefert eine Analyse der Ergebnisse und bewertet den gewählten Ansatz im Hinblick auf Praxistauglichkeit, Skalierbarkeit und mögliche Optimierungen. Abschließend werden in Kapitel 5 die wichtigsten Erkenntnisse zusammengefasst und ein Ausblick auf weiterführende Fragestellungen gegeben. 

 

1.2 Vorgehensweise der Arbeit 

Zunächst werden die theoretischen Grundlagen der Containerisierung in der Softwareentwicklung erarbeitet. Dabei wird ein besonderer Fokus auf die Rolle von Docker als Standardlösung zur Containerverwaltung gelegt. Im Rahmen dessen erfolgt eine Erläuterung der grundlegenden Konzepte wie Images, Container, Netzwerke und Volumes. Aufbauend auf den zuvor gewonnenen Erkenntnissen erfolgt eine vertiefte Betrachtung der Nutzung von Datenbanksystemen innerhalb containerisierter Umgebungen. In diesem Zusammenhang wird insbesondere die Wahl von MariaDB als relationales Datenbanksystem im Kontext containerisierter Architekturen begründet. 

Der praktische Teil der Arbeit beginnt mit der Einrichtung einer containerisierten MariaDB-Instanz mittels Docker Compose. Auf dieser Grundlage wird eine prototypische CRUD-Anwendung in Python entwickelt, die über eine REST-Schnittstelle mit der Datenbank kommuniziert. Das Ziel besteht darin, ein funktionales Zusammenspiel zwischen Applikations- und Datenbankcontainer zu realisieren, das die in der Theorie beschriebenen Konzepte nachvollziehbar und praktisch demonstriert. 

 

Zur Validierung der technischen Umsetzung wird ein Proof of Concept (PoC) durchgeführt, in dem typische Interaktionen, wie das Erstellen, Abrufen, Aktualisieren und Löschen von Datensätzen, getestet und dokumentiert werden. Im Rahmen der Analyse werden zudem die Benutzerfreundlichkeit des Deployments, die Ressourceneffizienz und die Skalierbarkeit der entwickelten Lösung untersucht. 

 

2 Containerbasierte Virtualisierung 

In diesem Kapitel werden die Grundlagen zum Verständnis der Virtualisierung gelegt. 

 

2.1 Defintion Virtualisierung  

Das Konzept der virtuellen Maschine wurde erstmals in den 1960er Jahren von IBM entwickelt, mit dem Ziel, einen gleichzeitigen, interaktiven Zugriff auf einen Großrechner zu ermöglichen. In der Vergangenheit repräsentierte jede virtuelle Maschine (VM) eine Instanz der physischen Maschine. Dies führte bei den Benutzern zur Illusion, dass sie direkt auf die physische Maschine zugreifen (Susanta Nanda, Department of Computer sciende, S. 1). Der Autor Matthew Portony beschreibt diesen Begriff wie folgt: „ In der Informatik bedeutet Virtualisierung oft die Abstraktion einer physischen Komponente in ein logisches Software-Objekt. Durch Virtualisierung eines Objekts ist es oft möglich, die Ressource besser zu nutzen, die durch das Objekt zur Verfügung gestellt wird. So bieten etwa virtuelle Local Area Networks (Lan), oder Virtual Local Area Networks (VLANs) eine bessere Netzwerk-Performance und Handhabbarkeit, wenn sie von der physischen Hardware getrennt werden.“ (Portony, 2012, S. 2012) 

 

2.2 Virtuelle Maschine 

Eine Vm funktioniert wie ein eigenständiger Computer, der jedoch nicht über die Hardware eines physischen Computers verfügt, sondern durch einen Hypervisor verwaltet wird.  Die Autoren Gaentzsch und Pohlmann beschreiben den Hypervisor wie folgt: „ Der Hypervisor ist eine Softwarekomponente, die auf einem Computer oder Server (Host-System), innerhalb eines vorhandenen Betriebssystems, ausgeführt wird. Der Hypervisor, auch als Virtual Machine Monitor (VMM) bezeichnet, hat dabei die Aufgabe, die Ressourcen des Computers, wie beispielsweise Prozessoren, den Arbeitsspeicher, den Festplattenspeicher, die Netzwerkverbindungen und vieles mehr, an eine oder mehrere virtuelle Maschinen zu verteilen und den Zugriff darauf zu verwalten. Der Hypervisor hat somit eine vermittelnde Funktion zwischen virtuellen Maschinen (Gast-System) und dem Virtualisierungsserver (Host-System).“ (Gaentzsch, Pohlmann, 2015, S.9).  

In der Literatur wird Zwischen zwei Typen von Hypervisoren unterschieden. Die Folgenden beiden Abbildung veranschulichen den Unterschied dieser beiden Typen.  

 

Abbildung 1: Typ 1 Hypervisor (Rick Goldman ) 

Ein Typ-1-Hypervisor wird direkt auf der physischen Hardware ausgeführt, ohne ein darunterliegendes Betriebssystem. In diesem Fall ist VMM ein kompakter Code, dessen Hautaufgabe in der Zuteilung und Verwaltung der Systemressoourcen an die virtuellen Maschinen liegt. Da kein Betriebssystem zwischen Harware und VMM vorhanden ist, übernimmt der Hypervisor direkt die Kontrolle über Prozessor, Speicher und Input/ Output Komponenten (I/O-Komponenten) (Desai, Oza, Sharma, Patel).  

 

Abbildung 2: Typ 2 Hypervisor (Rick Goldman) 

Ein Typ-II-Hypervisor wird auch als "Hosted Hypervisor" bezeichnet, da er als normale Anwendung innerhalb eines bestehenden Betriebssystems – dem sogenannten Host-Betriebssystem – ausgeführt wird. Der Hypervisor wird vom Host-System wie ein gewöhnlicher Prozess behandelt und nicht speziell priorisiert. In dieser Architektur übernimmt das Host-Betriebssystem sämtliche I/O-Operationen im Auftrag der virtuellen Maschinen (Desai, Oza, Sharma, Patel) 

Wenn ein Gastbetriebssystem eine I/O-Anfrage stellt, wird diese zunächst vom Hypervisor erkannt und anschließend vom Host-System an die entsprechenden Gerätetreiber weitergeleitet. Nach Abschluss der I/O-Operation wird die Antwort über den gleichen Weg zurück an das Gastbetriebssystem übermittelt. 
Im Gegensatz zu physischen Geräten, auf denen nur ein Betriebssystem und nur wenige Applikationen laufen können, können viele VMs gleichzeitig auf einem Rechner laufen und in diesen Vms können unterschiedliche Betriebssystem laufen, die dann wieder unterschiedliche Applikationen laufen lassen können. Virtuelle Maschinen bestehen aus einem Satz von Daten, die die virtuelle Maschine beschreiben. Zu den Hauptdateien zählen Konfigurationsdateien und virtuelle Diskdateien. Die erste Kategorie beschreibt die Ressourcen, die virtuellen Maschinen zur Verfügung stehen. 

Eine virtuelle Maschine kann mit einem oder mehreren Prozessoren betrieben werden. Die Zuweisung eines einzigen Prozessors stellt den einfachsten Fall dar. (Portony, 2012, S.59 ff.) 

 

2.3 Containisierung 

Das am weitesten verbreitete Container-Virtualisierungs-system ist Docker. Anhand dessen werden im Folgenden die grundlegenden Konzepte der Containervirtualisierung erklärt.  

Container verändern grundlegend die Art und Weise, wie Software entwickelt, verteilt und ausgeführt wird. Entwickler können Software lokal erstellen und dabei sicher sein, dass diese unabhängig von der Hast-Umgebung identisch ausgeführt wird. Dabei spielt es keine Rolle, ob dies auf einem Rack in der IT-Abteilung, dem Laptop eines Benutzers oder einem Cluster in der Cloud geschieht (Mouat, 2016, S.3). Ein Container stellt im Kern einen isolierten Prozess dar, der ein eigenes Dateisystem verwendet. Der entscheidende Vorteil liegt in der Schaffung einer einheitlichen Ausführungsumgebung für alle Beteiligten durch den Einsatz von Containern. Ein Container gewährleistet das Verpacken einer Anwendung mit allen dazugehörigen Dependencies, sodass eine Anwendung schnell und zuverlässig von einer Computerumgebung zur anderen ausgeführt werden kann. (https://www.docker.com/resources/what-container, abgerufen am 14.07.2025). Dadurch kann eine zuverlässige Ausführung von Anwendungen unabhängig vom individuellen System jedes Entwicklers sichergestellt werden. Die Verwendung unterschiedlicher Versionen von Frameworks oder Abhängigkeiten kann zu Problemen führen, wenn keine Containerisierung stattfindet. Dies kann dazu führen, dass eine Anwendung nicht korrekt startet oder fehlerhaft funktioniert (Geisler & Kettner, 2019, S.32,40).  
Container sind eine Kapselung einer Anwendung mit ihren Abhängigkeiten. Auf den ersten Blick scheinen sie nur eine leichtgewichtige Form von virtuellen Maschinen (VMs) zu sein. Wie auch eine VM enthält ein Container eine isolierte Instanz eines Betriebssystems (OS), mit der Anwendungen ausgeführt werden können (Mouat, 2016, S.3).  

 

2.4 Vergleich Container und Virutelle maschine 

Im Hinblick auf die angestrebten Ziele lassen sich VMS und Container als vergleichbar erachten. Wie in den vorherigen Kapiteln erläutert, können virtuelle Maschinen (VMs) und Container dazu genutzt werden, Anwendungen und Web-Anwendungen möglichst isoliert auf nur einer physischen Maschine auszuführen. Obwohl das Ziel identisch ist, unterscheiden sich die Funktionsweise und der Aufbau.  

Bei einer virtuellen Maschine erfolgt die Simulation der kompletten Hardware eines Computers durch Software. In der Konsequenz entsteht für die virtuelle Maschine die Illusion, auf echter physischer Hardware zu laufen. Die Generierung einer Replika diverser Hardwarekomponenten bedingt jedoch einen signifikanten Einsatz von Systemressourcen. 

Demgegenüber greifen Container direkt auf die vorhandene Infrastruktur des Host-Systems zu, insbesondere auf dessen Dateisystem und Kernel. Container operieren nicht in einer vollständig isolierten virtuellen Umgebung, sondern verhalten sich vielmehr wie voneinander abgeschottete Prozesse auf dem Host-System. Da bei Containern keine Hardwareemulation erforderlich ist, ist der Speicherplatzbedarf deutlich geringer und der Startvorgang wesentlich schneller als bei virtuellen Maschinen. Virtuelle Maschinen sind im Gegensetz zu Containern besser voneinander Isoliert und bieten daruch noch mehr Sicherheit (Öggel, Kofler, 2018 S. 32 f.). 

Die Folgenden Abbildungen verdeutlicht den unterschiedlichen Aufbau von Vvirtuellen maschinen und Containern.  

 

Abbildung 3: Drie VMs, die auf einem Host laufen (Mouat, 2016, S.5) 

 

Abbildung 4: drei Container, die auf einem Host laufen (Mouat, 2016, S.5) 

In Abbildung 1 werden drei Anwendungen dargestellt, die in separaten virtuellen Maschinen auf einem Host ausgeführt werden. Der Hypervisor ist eine essenzielle Komponente, die die Erstellung und Ausführung von virtuellen Maschinen (VMs) ermöglicht. Darüber hinaus steuert er den Zugriff auf das zugrunde liegende Betriebssystem und die Hardware und interpretiert bei Bedarf Systemaufrufe. Für jede VM ist eine vollständige Kopie des Betriebssystems, der ausgeführten Anwendung und aller unterstützenden Bibliotheken erforderlich. 

Abbildung 2 zeigt eine alternative Möglichkeit, wie dieselben drei Anwendungen in einem containerisierten System ausgeführt werden könnten. Im Gegensatz zu VMs wird der Kernel des Hosts mit den ausgeführten Containern geteilt. Dies bedeutet, dass Container immer auf den gleichen Kernel wie der Host beschränkt sind. Die Anwendungen Y und Z verwenden dieselben Bibliotheken und können diese Daten gemeinsam nutzen, anstatt redundante Kopien zu haben. Die Container-Engine ist für das Starten und Stoppen von Containern verantwortlich, ähnlich wie der Hypervisor auf einer VM. Die in Containern ausgeführten Prozesse entsprechen den nativen Prozessen auf dem Host und verursachen keine Overheads, die mit der Ausführung des Hypervisors verbunden sind. 

Sowohl VMs als auch Container können dazu verwendet werden, Anwendungen von anderen Anwendungen zu isolieren, die auf demselben Host ausgeführt werden. VMs bieten einen zusätzlichen Grad an Isolation vom Hypervisor und sind eine bewährte und kampferprobte Technologie. Container sind eine vergleichsweise neue Entwicklung, und viele Unternehmen zögern, den Isolationsfunktionen von Containern vollständig zu vertrauen, bevor sie sich bewährt haben. Aus diesem Grund sind Hybridsysteme mit Containern, die innerhalb von VMs ausgeführt werden, weit. verbreitet, um die Vorteile beider Technologien zu nutzen (Mouat, 2016, S.5).  

Container sind grundsätzlich unveränderlich. Das hat zu Folge, dass Sftware innerhalb eines Containers nicht aktualisiert werden kann. Der bestehende Container muss enfernt und durch eine neue Instanz mit der aktualisierten Software ersetzt werden. Des Weitern unterscheidet sich die Lebensdauer deutlich von der der  virtuellen Maschine. Container existieren nur so lange, wie sie benötigt werden. Sobald dies nicht mehr der Fall ist, lassen sie sich problemlos löschen und bei Bedarf in kürzester Zeit neu erzeugen. Bei virtuellen Maschinen ist dieser Prozess deutlich aufwendiger, da jedes Mal ein vollständiges Betriebssystem installiert werden muss (Geisler & Kettner, 2019, S.38).  

 

2.5 Docker Grundprinzipien  

In diesem Abschnitt wird die grundlegende Architektur von Docker, sowie das Nutzen der selbigen erkläutert.  

Docker ist eine Plattform zur containerbasierten Virtualisierung, die es ermöglicht, Anwendungen unabhängig von ihrer Umgebung zu erstellen, bereitzustellen und auszuführen. Innerhalb weniger Jahre hat sich Docker von einem neuen Werkzeug zu einem etablierten Industriestandard entwickelt – insbesondere für die Lösung eines zentralen Problems der Softwareentwicklung: der einheitlichen und effizienten Bereitstellung von Anwendungen. Vor der Verbreitung von Docker war die Softwarebereitstellung häufig mit komplexen und fehleranfälligen Prozessen verbunden. Die Entwicklungs- und Auslieferungspipeline setzte sich aus einer Vielzahl unterschiedlicher Technologien zusammen, wie etwa virtuellen Maschinen, Konfigurationsmanagement-Tools, Paketverwaltungssystemen oder Abhängigkeitsnetzwerken. Diese Komponenten mussten individuell konfiguriert, gewartet und aufeinander abgestimmt werden – häufig durch spezialisierte Fachkräfte. Die heterogene Tool-Landschaft erschwerte eine standardisierte und portable Ausführung von Anwendungen erheblich (Miell, Sayers, chapter 1).  

Docker Images:  

Ein Docker-Image stellt die Grundlage für jeden Container dar und bildet ein schreibgeschütztes Abbild eines Dateisystems. Es enthält alle notwendigen Komponenten zur Ausführung einer Anwendung. Images sind somit das zentrale Konstrukt in Docker, von dem alle Containerinstanzen abgeleitet werden. 

Im Gegensatz zu virtuellen Maschinen, bei denen Änderungen direkt auf das virtuelle System wirken, bleibt das ursprüngliche Image eines Containers während seiner Ausführung stets unverändert. Jegliche durch den Container vorgenommenen Modifikationen – sei es durch neue Dateien, Konfigurationsänderungen oder temporäre Daten – werden in einem sogenannten Overlay-Dateisystem gespeichert. Dieses befindet sich in einem separaten Verzeichnis auf dem Host-System und ermöglicht eine klare Trennung zwischen konstanten Image-Inhalten und dynamischen Container-Daten. 

Durch diese Architektur ist es möglich, mehrere Container gleichzeitig aus demselben Image zu erzeugen und auszuführen, ohne dass diese sich gegenseitig beeinflussen. Im Internet, insbesondere auf Docker Hub, stehen zahlreiche Images zum Download bereit, die meisten davon kostenlos. Images können wie einen Werkzeugkasten genutzt werden, um daraus eigene Container abzuleiten oder selsbt neue Images zu kombinieren.  (Öggl, Kofler, 2023 , S. 30) 

Es gibt zwei Möglichkeiten, Docker-Images zu erstellen. Eine Option ist das sogenannte Commit, bei dem der Zustand eines laufenden Containers als neues Image gespeichert wird. In der Regel basiert dieses Image auf einem bereits existierenden Image wie Ubuntu oder Fedora. Die gängigere und professionellere Methode ist die Nutzung einer Dockerfile, die alle Anweisungen zur Image-Erstellung enthält. Mit dem Befehl "docker build" wird daraus ein neues, reproduzierbares Image samt aller definierten Abhängigkeiten generiert (Amit M Potdara , Narayan D Gb, Shivaraj Kengondc, Mohammed Moin Mullad).  

Docker Container:  

Docker-Container basieren auf dem zuvor erstellten Image. Um eine Anwendung isoliert auszuführen, enthält der Container alle dafür benötigten Komponenten. Je nach Einsatzzweck kann das zugrunde liegende Image individuell an die Anforderungen der jeweiligen Software angepasst werden. Ein Beispiel ist die Nutzung einer Anwendung auf einem Ubuntu-Betriebssystem in Kombination mit dem Webserver Nginx. In diesem Fall werden die entsprechenden Bestandteile in der zugehörigen Dockerfile definiert. Mit dem Befehl "docker run" wird daraufhin ein Container gestartet, der das entsprechende Image mit Ubuntu und Nginx verwendet und unmittelbar ausgeführt wird (Amit M Potdara , Narayan D Gb, Shivaraj Kengondc, Mohammed Moin Mullad). 

Docker Volumes:  

Wird ein Docker-Image aktualisiert, etwa aufgrund einer neuen Softwareversion, wird der laufende Container gestoppt und durch einen neuen ersetzt. Dieser Vorgang erfolgt jedoch nicht automatisch und muss manuell angestoßen werden. Während der Programmcodes im Image dadurch problemlos aktualisiert werden kann, stellt sich die Frage, was mit den im laufenden Betrieb erzeugten Dateien geschieht. Um Datenverluste zu vermeiden, stellt Docker sogenannte Volumes bereit. Diese sind Verzeichnisse auf dem Host-Dateisystem, die außerhalb des Containers liegen. In ihnen werden persistente Daten abgelegt, die auch beim Austausch eines Containers erhalten bleiben. Bei einem Datenbank-Container befinden sich beispielsweise die Datenbankdateien im Volume; bei einem Webserver liegen dort HTML-Dokumente, PHP-Skripte und weitere Webinhalte.  Standardmäßig erstellt Docker beim Anlegen eines Containers ein zugehöriges Volume im Verzeichnis /var/lib/docker/volumes (bzw. .local/share/docker/volumes unter Linux) und vergibt einen UUID-basierten Namen. Zur besseren Verwaltung können Volumes benannt oder ein eigener Speicherort festgelegt werden. Über den Befehl docker inspect lässt sich der Speicherort eines Volumes jederzeit ermitteln. (Öggl, Kofler, 2023 , S. 30 f.) 

Docker Compose 

Moderne Softwareanwendungen bestehen häufig aus mehreren miteinander kommunizierenden Diensten, die jeweils in separaten Docker-Containern ausgeführt werden. Um diese Dienste effizient zu orchestrieren, wird Docker Compose eingesetzt. Docker Compose ist ein Werkzeug zur Ausführung von Multi-Container-Anwendungen in Docker. Es basiert auf einer YAML-Datei, die die Konfiguration aller beteiligten Dienste enthält. Diese Datei fasst mehrere Containerdefinitionen zusammen und ermöglicht es, sämtliche Dienste mit einem einzigen Befehl – docker-compose up – gleichzeitig zu starten.   

Zur Nutzung von Docker Compose sind drei Schritte erforderlich:   

    Die Konfiguration eines Containers wird in einer Dockerfile definiert.  

    Die YAML-Datei enthält die Definition aller gewünschten Dienste.  

    Mit dem Ausführen von docker-compose up wird die Anwendung gestartet.  

Docker Compose kann sowohl für komplexe Microservice-Architekturen als auch für Einzelanwendungen verwendet werden. Zusätzlich unterstützt es das Bauen von Images, das Skalieren von Containern sowie das Neustarten gestoppter Instanzen. Es stellt eine Abstraktion über den regulären Docker-Befehlen dar und vereinfacht somit die Verwaltung und Ausführung verteilter Anwendungen (Kinnary jangla, S.78) 